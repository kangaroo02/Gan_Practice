{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/isaiah/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show System RAM Memory:\n",
      "\n",
      "\n",
      "MemTotal:        8041524 kB\n",
      "\n",
      "\n",
      "Show Devices:\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3542228368263938222\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 141819904\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13645532332902043770\n",
      "physical_device_desc: \"device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Show System RAM Memory:\\n\\n\")\n",
    "!cat /proc/meminfo | egrep \"MemTotal*\"\n",
    "print(\"\\n\\nShow Devices:\\n\\n\"+str(device_lib.list_local_devices()))\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "def plot_images(images, n):\n",
    "    for i in range(n * n):\n",
    "        if(i >= len(images)):\n",
    "            break\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data # change from opencv-bgr to matplot-rgb\n",
    "        pyplot.imshow(images[i][...,::-1].astype('uint8'))\n",
    "    pyplot.show()\n",
    "\n",
    "# load all images in a directory into memory\n",
    "def load_images(start_point, number_limit, archive_name, size=(256,256)):\n",
    "    # print(dirlist)\n",
    "    src_list = list()\n",
    "    archive = zipfile.ZipFile(archive_name, 'r')\n",
    "    dirlist = archive.namelist()[1:]\n",
    "    with archive as zfile:\n",
    "\n",
    "        # enumerate filenames in directory, assume all are images\n",
    "        for index in range(start_point, start_point + number_limit):\n",
    "            # load and resize the image\n",
    "\n",
    "            data = zfile.read(dirlist[index])\n",
    "            imgfile = cv2.imdecode(np.frombuffer(data, np.uint8), 1)\n",
    "\n",
    "            resize = cv2.resize(imgfile, size)\n",
    "\n",
    "            # cv2.imshow(\"0\", resize)\n",
    "            # cv2.waitKey(10)\n",
    "            # pixels = img_to_array(resize)\n",
    "            # print(resize.shape)\n",
    "            # print(index)\n",
    "            src_list.append(resize)\n",
    "\n",
    "    return asarray(src_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def prepare_real_samples(file):\n",
    "    # load compressed arrays\n",
    "    # data = load(filename)\n",
    "    # load the face dataset\n",
    "    # color_images = data['arr_0'].astype('uint8')\n",
    "    color_images = file\n",
    "    \n",
    "    # print(type(src_images))\n",
    "    gray_images = color_images.astype('uint8')\n",
    "    gray_images [:,:,:,0] = color_images[:,:,:,0]/3 + color_images[:,:,:,1]/3 + color_images[:,:,:,2]/3\n",
    "    gray_images [:,:,:,1] = gray_images [:,:,:,0]\n",
    "    gray_images [:,:,:,2] = gray_images [:,:,:,0]\n",
    "    \n",
    "    # unpack arrays\n",
    "    X1 = gray_images\n",
    "    X2 = color_images\n",
    "\n",
    "    plot_images(color_images, 10)\n",
    "    plot_images(gray_images, 10)\n",
    "    \n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/isaiah/Downloads/train2014.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bfad14fdf8b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummery_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/isaiah/GAN_practice_no_git/performances/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdirlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/isaiah/Downloads/train2014.zip'"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/isaiah/Downloads/train2014.zip\"\n",
    "model_save_path = \"/home/isaiah/GAN_practice_no_git/models/\"\n",
    "summery_path = \"/home/isaiah/GAN_practice_no_git/performances/\"\n",
    "\n",
    "archive = zipfile.ZipFile(data_path, 'r')\n",
    "dirlist = archive.namelist()[1:]\n",
    "\n",
    "full_size = len(dirlist)\n",
    "full_size = 40000\n",
    "part_size = 100\n",
    "\n",
    "start_step = 0\n",
    "\n",
    "print(full_size)\n",
    "\n",
    "load_steps = int(full_size/part_size)\n",
    "load_steps = 1\n",
    "load_leftover = full_size%part_size\n",
    "\n",
    "\n",
    "print(\"load_steps\", load_steps)\n",
    "print(\"load_leftover\", load_leftover)\n",
    "\n",
    "#### define everything ####\n",
    "\n",
    "\n",
    "\n",
    "#### train part!! ####\n",
    "for step in range(start_step, load_steps + 1):\n",
    "    start_point = step * part_size\n",
    "\n",
    "    if (step < load_steps):\n",
    "        number_limit = part_size\n",
    "    else:\n",
    "        number_limit = load_leftover\n",
    "        if load_leftover == 0:\n",
    "            break\n",
    "\n",
    "    src_images = load_images(start_point, number_limit, data_path)\n",
    "    dataset = prepare_real_samples(src_images)\n",
    "    print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "\n",
    "    #### train here!! ####\n",
    "\n",
    "    del src_images\n",
    "    del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
